from fastapi import FastAPI, File, UploadFile, HTTPException, Depends
from loguru import logger
from typing import Optional
import os
import sys
import traceback
import uuid # ğŸ’¡ NEW: Import uuid for S3 key generation, though file_upload_service might handle it.
import boto3 # ğŸ’¡ NEW: Import boto3, required for S3 access
from botocore.exceptions import ClientError # ğŸ’¡ NEW: Import ClientError

# RQ/Redis imports
import redis
from rq import Queue, Retry
from rq.job import Job

# Add the app directory to the Python path to help with imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from . import modelsÂ 
from . import file_upload_service # This service will be updated to handle S3 uploads.

# --- Configuration & Initialization ---
app = FastAPI()

# âŒ REMOVED: UPLOAD_DIR is no longer relevant for S3
# UPLOAD_DIR = "uploads"Â 

# --- AWS S3 Configuration ---
# ğŸ’¡ NEW: Environment variables for S3 connection
S3_BUCKET_NAME = os.environ.get('S3_BUCKET_NAME')
AWS_REGION = os.environ.get('AWS_REGION', 'us-east-1') # Default to a common region

def get_s3_client():
    """Initializes and returns the S3 client using environment credentials."""
    if not S3_BUCKET_NAME:
        logger.error("[MAIN] âŒ S3_BUCKET_NAME environment variable is not set.")
        raise HTTPException(status_code=500, detail="S3 configuration missing.")
    try:
        # Boto3 automatically uses AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY from env vars
        return boto3.client('s3', region_name=AWS_REGION)
    except Exception as e:
        logger.error(f"[MAIN] âŒ Failed to initialize S3 client: {e}")
        raise HTTPException(status_code=500, detail="AWS S3 service failed to initialize.")


# Initialize Redis connection and RQ Queue (NO CHANGE)
REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379/0')
logger.info(f"[MAIN] Connecting to Redis at: {REDIS_URL}")
try:
Â  Â  redis_conn = redis.from_url(REDIS_URL)
Â  Â  redis_conn.ping()Â 
Â  Â  logger.info("[MAIN] âœ… Successfully connected to Redis")
except Exception as e:
Â  Â  logger.error(f"[MAIN] âŒ FATAL: Could not connect to Redis: {e}")
Â  Â  redis_conn = NoneÂ 

def get_analysis_queue():
Â  Â  if redis_conn is None:
Â  Â  Â  Â  raise HTTPException(status_code=503, detail="Analysis service is unavailable (Redis connection failed).")
Â  Â  return Queue('default', connection=redis_conn)

# --- 1. Root Endpoint (Health Check) ---
# ... (NO CHANGE to / and /health endpoints) ...
@app.get("/")
def read_root():
Â  Â  redis_status = "connected" if redis_conn else "disconnected"
Â  Â  return {
Â  Â  Â  Â  "status": "ok",Â 
Â  Â  Â  Â  "message": "PodiumAI backend is running.",
Â  Â  Â  Â  "redis": redis_status
Â  Â  }

# --- Health check endpoint ---
@app.get("/health")
def health_check():
Â  Â  try:
Â  Â  Â  Â  if redis_conn:
Â  Â  Â  Â  Â  Â  redis_conn.ping()
Â  Â  Â  Â  Â  Â  queue = Queue('default', connection=redis_conn)
Â  Â  Â  Â  Â  Â  queue_length = len(queue)
Â  Â  Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  Â  Â  "status": "healthy",Â 
Â  Â  Â  Â  Â  Â  Â  Â  "redis": "connected",
Â  Â  Â  Â  Â  Â  Â  Â  "queue_length": queue_length
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  return {"status": "unhealthy", "redis": "disconnected"}
Â  Â  except Exception as e:
Â  Â  Â  Â  return {"status": "unhealthy", "redis": str(e)}


# --- 2. File Upload Endpoint (Minor Change) ---
# This endpoint now saves to S3 via the service and returns the S3 Key.
@app.post("/upload", response_model=models.UploadResponse)
async def upload_audio(file: UploadFile = File(...)):
Â  Â  try:
Â  Â  Â  Â  logger.info(f"[MAIN] ğŸ“¤ Receiving file upload: {file.filename}")
        # ğŸ’¡ CHANGE: file_upload_service.save_audio_file must now return the S3 key/ID, not a local file path/ID.
Â  Â  Â  Â  result = await file_upload_service.save_audio_file(file)
Â  Â  Â  Â  logger.info(f"[MAIN] âœ… File uploaded to S3 with Key: {result.file_id}")
Â  Â  Â  Â  return resultÂ 
Â  Â  except ClientError as e: # Catch S3-specific errors
        logger.error(f"[MAIN] âŒ S3 Upload failed: {e}")
        raise HTTPException(status_code=500, detail=f"S3 Upload Error: {e.response['Error']['Message']}")
Â  Â  except Exception as e:
Â  Â  Â  Â  logger.error(f"[MAIN] âŒ Error uploading file: {e}", exc_info=True)
Â  Â  Â  Â  raise HTTPException(status_code=500, detail=f"An unexpected error occurred: {str(e)}")

# --- 3. Submit Analysis Job Endpoint (MAJOR Change) ---
# The path variable will now hold the S3 key, and local file checks are removed.
@app.post("/api/v1/analysis/submit", response_model=models.AnalysisStatusResponse)
async def submit_analysis_job(
Â  Â  request: models.AnalysisRequest,
Â  Â  queue: Queue = Depends(get_analysis_queue)
):
Â  Â  # ğŸ’¡ CHANGE: We assume file_id is the S3 Key.
Â  Â  logger.info(f"[MAIN] ğŸš€ Received analysis submission for S3 Key: {request.file_id}")
Â  Â  s3_key = request.file_id # Rename for clarity, this is the S3 Key/Path
Â  Â Â 
Â  Â  # âŒ REMOVED: No more local file path check. The worker handles S3 download and not-found errors.
Â  Â  # file_path = os.path.join(UPLOAD_DIR, f"{request.file_id}.m4a")
Â  Â Â 
Â  Â  # if not os.path.exists(file_path):
Â  Â  # Â  Â  logger.error(f"[MAIN] âŒ File not found during submission: {file_path}")
Â  Â  # Â  Â  raise HTTPException(status_code=404, detail=f"File associated with ID {request.file_id} not found on server.")
Â  Â Â 
    # âŒ REMOVED: No more local file size check.
Â  Â  # file_size = os.path.getsize(file_path)
Â  Â  # logger.info(f"[MAIN] ğŸ“ File exists: {file_path} ({file_size} bytes)")
Â  Â  logger.info(f"[MAIN] ğŸ“ Transcript length: {len(request.transcript)} chars")
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  # Enqueue the job with the S3 key as the 'file_path' argument
Â  Â  Â  Â  job = queue.enqueue(
Â  Â  Â  Â  Â  Â  'app.analysis_worker.perform_analysis_job',
Â  Â  Â  Â  Â  Â  request.file_id,Â 
Â  Â  Â  Â  Â  Â  s3_key,Â # ğŸ’¡ CHANGE: Pass the S3 Key instead of the local file_path
Â  Â  Â  Â  Â  Â  request.transcript,
Â  Â  Â  Â  Â  Â  job_id=f"analysis-{request.file_id}",Â 
Â  Â  Â  Â  Â  Â  retry=Retry(max=3),
Â  Â  Â  Â  Â  Â  job_timeout='10m',
Â  Â  Â  Â  Â  Â  result_ttl=3600,Â  # Keep results for 1 hour
Â  Â  Â  Â  Â  Â  failure_ttl=3600Â  # Keep failure info for 1 hour
Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  logger.info(f"[MAIN] âœ… Job enqueued successfully")
Â  Â  Â  Â  logger.info(f"[MAIN]Â  Â  Job ID: {job.id}")
Â  Â  Â  Â  logger.info(f"[MAIN]Â  Â  Initial status: {job.get_status()}")
Â  Â  Â  Â  logger.info(f"[MAIN]Â  Â  Function: {job.func_name}")
Â  Â  Â  Â Â 
Â  Â  Â  Â  return models.AnalysisStatusResponse(
Â  Â  Â  Â  Â  Â  job_id=job.id,
Â  Â  Â  Â  Â  Â  status=job.get_status(),Â 
Â  Â  Â  Â  Â  Â  result=None
Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  except Exception as e:
Â  Â  Â  Â  logger.error(f"[MAIN] âŒ Failed to enqueue analysis job: {e}", exc_info=True)
Â  Â  Â  Â  raise HTTPException(
Â  Â  Â  Â  Â  Â  status_code=500,Â 
Â  Â  Â  Â  Â  Â  detail=f"Failed to submit analysis job to the queue: {str(e)}"
Â  Â  Â  Â  )

# ... (NO CHANGE to /debug/test-worker-import and /api/v1/analysis/status/{job_id} endpoints) ...
@app.get("/debug/test-worker-import")
def test_worker_import():
Â  Â  """Test if we can import the worker function"""
Â  Â  try:
Â  Â  Â  Â  from . import analysis_worker
Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  "status": "success",
Â  Â  Â  Â  Â  Â  "function_exists": hasattr(analysis_worker, 'perform_analysis_job'),
Â  Â  Â  Â  Â  Â  "function_path": "app.analysis_worker.perform_analysis_job",
Â  Â  Â  Â  Â  Â  "module_file": analysis_worker.__file__ if hasattr(analysis_worker, '__file__') else "unknown"
Â  Â  Â  Â  }
Â  Â  except Exception as e:
Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  "status": "error",
Â  Â  Â  Â  Â  Â  "error": str(e),
Â  Â  Â  Â  Â  Â  "traceback": traceback.format_exc()
Â  Â  Â  Â  }

@app.get("/api/v1/analysis/status/{job_id}", response_model=models.AnalysisStatusResponse)
def get_analysis_status(
Â  Â  job_id: str,Â 
Â  Â  queue: Queue = Depends(get_analysis_queue)
):
Â  Â  logger.info(f"[MAIN] ğŸ” Checking status for job: {job_id}")
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  job = queue.fetch_job(job_id)
Â  Â  Â  Â Â 
Â  Â  Â  Â  if not job:
Â  Â  Â  Â  Â  Â  logger.warning(f"[MAIN] âš ï¸Â  Job not found: {job_id}")
Â  Â  Â  Â  Â  Â  raise HTTPException(status_code=404, detail="Job not found.")
Â  Â  Â  Â Â 
Â  Â  Â  Â  status = job.get_status()
Â  Â  Â  Â  logger.info(f"[MAIN] ğŸ“Š Job {job_id} status: {status}")
Â  Â  Â  Â Â 
Â  Â  Â  Â  if status == 'finished':
Â  Â  Â  Â  Â  Â  result_data = job.result
Â  Â  Â  Â  Â  Â  logger.info(f"[MAIN] âœ… Job completed successfully")
Â  Â  Â  Â  Â  Â  return models.AnalysisStatusResponse(
Â  Â  Â  Â  Â  Â  Â  Â  job_id=job.id,
Â  Â  Â  Â  Â  Â  Â  Â  status=status,
Â  Â  Â  Â  Â  Â  Â  Â  result=result_data,Â 
Â  Â  Â  Â  Â  Â  Â  Â  error=None
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  elif status == 'failed':
Â  Â  Â  Â  Â  Â  error_message = str(job.exc_info) if job.exc_info else "Job failed for an unknown reason."
Â  Â  Â  Â  Â  Â  logger.error(f"[MAIN] âŒ Job failed: {error_message}")
Â  Â  Â  Â  Â  Â  return models.AnalysisStatusResponse(
Â  Â  Â  Â  Â  Â  Â  Â  job_id=job.id,
Â  Â  Â  Â  Â  Â  Â  Â  status=status,
Â  Â  Â  Â  Â  Â  Â  Â  error=error_message
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Job is still queued or started
Â  Â  Â  Â  return models.AnalysisStatusResponse(
Â  Â  Â  Â  Â  Â  job_id=job.id,
Â  Â  Â  Â  Â  Â  status=status,
Â  Â  Â  Â  Â  Â  result=None,
Â  Â  Â  Â  Â  Â  error=None
Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  except HTTPException:
Â  Â  Â  Â  raise
Â  Â  except Exception as e:
Â  Â  Â  Â  logger.error(f"[MAIN] âŒ Error checking job status: {e}", exc_info=True)
Â  Â  Â  Â  raise HTTPException(status_code=500, detail=f"Error checking job status: {str(e)}")
