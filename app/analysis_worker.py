# analysis_worker.py

import os
import logging
from typing import Dict, Any, Optional, List, Tuple
import time
import sys
import subprocess
import numpy as np
import soundfile as sf
import json

# --- IMPORTS FOR OPENAI (MANUAL HTTP) ---
import httpx
# ------------------------------------

import boto3
from botocore.exceptions import ClientError
from redis import Redis
from rq import WorkerÂ 

# Import ALL necessary functions and constants from the engine (UPDATED IMPORTS)
from analysis_engine import (Â 
Â  Â  detect_fillers_and_apologies,Â # New function
Â  Â  detect_repetitions_for_highlighting, # New function
    detect_custom_markers, # New function
Â  Â  score_confidence,Â 
Â  Â  initialize_emotion_model,
Â  Â  classify_emotion_simple,
Â  Â  calculate_pitch_stats, 
Â  Â  detect_acoustic_disfluencies, 
Â  Â  extract_audio_features,Â  Â  Â Â 
Â  Â  MAX_DURATION_SECONDS,
    TextMarker # Import new NamedTuple
)

# --- Configuration ---
S3_BUCKET_NAME = os.environ.get('S3_BUCKET_NAME')
AWS_REGION = os.environ.get('AWS_REGION', 'eu-north-1')Â 
TARGET_SR = 16000Â 
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")Â 

# --- Logging Setup ---
logging.basicConfig(
Â  Â  level=logging.INFO,
Â  Â  format='%(asctime)s | %(levelname)s | [WORKER] - %(message)s'
)
logger = logging.getLogger(__name__)

# --- S3 Client Initialization (Unchanged) ---
def get_s3_client():
Â  Â  if not S3_BUCKET_NAME:
Â  Â  Â  Â  logger.error("[WORKER] âŒ S3_BUCKET_NAME environment variable is not set.")
Â  Â  Â  Â  raise ValueError("S3_BUCKET_NAME is not configured.")
Â  Â  return boto3.client('s3', region_name=AWS_REGION)

try:
Â  Â  s3_client = get_s3_client()
Â  Â  logger.info(f"[WORKER] âœ… S3 Client initialized for bucket: {S3_BUCKET_NAME} in region: {AWS_REGION}")
except Exception as e:
Â  Â  logger.error(f"[WORKER] âŒ S3 Initialization failed: {e}")
Â  Â  raise
Â  Â Â 
# --- Global ML Model/Scaler Initialization (Unchanged) ---
try:
Â  Â  EMOTION_MODEL, EMOTION_SCALER, _ = initialize_emotion_model()Â 
Â  Â  logger.info("[WORKER] âœ… Emotion model and scaler initialized/loaded.")
except Exception as e:
Â  Â  logger.error(f"[WORKER] âŒ Failed to initialize emotion model: {e}", exc_info=True)
Â  Â  EMOTION_MODEL, EMOTION_SCALER = None, None

# --- Intelligent Feedback Generation Function (Unchanged) ---
def generate_intelligent_feedback(transcript: str, metrics: Dict[str, Any]) -> List[str]:
Â  Â  """Generates tailored feedback and recommendations using a direct HTTP request."""
    # ... (function body remains unchanged) ...
Â  Â  if not OPENAI_API_KEY:
Â  Â  Â  Â  logger.warning("[OPENAI] Skipping feedback generation: OPENAI_API_KEY not set.")
Â  Â  Â  Â  return ["Error: Feedback service is unavailable (API key not configured)."]
Â  Â  Â  Â Â 
Â  Â  acoustic_count = metrics.get('acoustic_disfluency_count', 0)
Â  Â Â 
Â  Â  metrics_summary = json.dumps({
Â  Â  Â  Â  "Duration (Seconds)": metrics.get('duration_seconds', 0.0),
Â  Â  Â  Â  "Total Words": metrics.get('total_words', 0),
Â  Â  Â  Â  "Pace (Words per Minute)": metrics.get('speaking_pace', 0),
Â  Â  Â  Â  "Filler Word Count": metrics.get('filler_word_count', 0),
Â  Â  Â  Â  "Repetition Count": metrics.get('repetition_count', 0),
Â  Â  Â  Â  "Acoustic Disfluency Count (Blocks/Stutters)": acoustic_count,Â 
Â  Â  Â  Â  "Silence Ratio": f"{metrics.get('silence_ratio', 0.0) * 100:.2f}%",
Â  Â  Â  Â  "Emotion Detected": metrics.get('emotion'),
Â  Â  Â  Â  "Confidence Score": f"{metrics.get('confidence_score', 0.0):.2f}",
Â  Â  }, indent=2)
Â  Â Â 
Â  Â  system_prompt = (
Â  Â  Â  Â  "You are an expert speech coach. Your task is to analyze the provided speech transcript and metrics. "
Â  Â  Â  Â  "Generate a structured list of exactly three highly specific, actionable, and encouraging recommendations "
Â  Â  Â  Â  "for the user to improve their public speaking. "
Â  Â  Â  Â  "The response MUST be a JSON array of strings wrapped in a single key called 'recommendations' "
Â  Â  Â  Â  "(e.g., {'recommendations': ['Tip 1', 'Tip 2', 'Tip 3']}). Do not include any introductory text, "
Â  Â  Â  Â  "closing remarks, or numbering outside the array."
Â  Â  )
Â  Â Â 
Â  Â  user_prompt = (
Â  Â  Â  Â  f"Transcript (First 1000 characters):\n---\n{transcript[:1000]}...\n---\n"
Â  Â  Â  Â  f"Analysis Metrics:\n---\n{metrics_summary}\n---\n"
Â  Â  Â  Â  "Based on these, generate a JSON object with a single key 'recommendations' containing a list of 3 specific recommendations."
Â  Â  )

Â  Â  api_url = "https://api.openai.com/v1/chat/completions"
Â  Â  headers = {
Â  Â  Â  Â  "Authorization": f"Bearer {OPENAI_API_KEY}",
Â  Â  Â  Â  "Content-Type": "application/json"
Â  Â  }
Â  Â Â 
Â  Â  payload = {
Â  Â  Â  Â  "model": "gpt-4o-mini",
Â  Â  Â  Â  "messages": [
Â  Â  Â  Â  Â  Â  {"role": "system", "content": system_prompt},
Â  Â  Â  Â  Â  Â  {"role": "user", "content": user_prompt}
Â  Â  Â  Â  ],
Â  Â  Â  Â  "response_format": {"type": "json_object"},Â 
Â  Â  Â  Â  "temperature": 0.7
Â  Â  }

Â  Â  try:
Â  Â  Â  Â  logger.info("[OPENAI] Calling Chat API manually using httpx...")
Â  Â  Â  Â Â 
Â  Â  Â  Â  with httpx.Client(trust_env=False) as client:
Â  Â  Â  Â  Â  Â  client.proxies = {}Â 
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  response = client.post(
Â  Â  Â  Â  Â  Â  Â  Â  api_url,
Â  Â  Â  Â  Â  Â  Â  Â  headers=headers,
Â  Â  Â  Â  Â  Â  Â  Â  json=payload,
Â  Â  Â  Â  Â  Â  Â  Â  timeout=60.0
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  response.raise_for_status()Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  feedback_data = response.json()
Â  Â  Â  Â  feedback_json_str = feedback_data['choices'][0]['message']['content']
Â  Â  Â  Â Â 
Â  Â  Â  Â  recommendation_data = json.loads(feedback_json_str)
Â  Â  Â  Â  recommendations = recommendation_data.get('recommendations', [])Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  if isinstance(recommendations, list) and all(isinstance(r, str) for r in recommendations):
Â  Â  Â  Â  Â  Â  logger.info(f"[OPENAI] Successfully generated {len(recommendations)} recommendations.")
Â  Â  Â  Â  Â  Â  return recommendations
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  logger.error(f"[OPENAI] Generated feedback was not a list of strings: {recommendation_data}")
Â  Â  Â  Â  Â  Â  return ["Feedback generation failed: Model returned incorrect format."]

Â  Â  except httpx.RequestError as e:
Â  Â  Â  Â  logger.error(f"[OPENAI] HTTP request error: {e}")
Â  Â  Â  Â  return [f"An error occurred connecting to the feedback service: {e.__class__.__name__}"]
Â  Â  except httpx.HTTPStatusError as e:
Â  Â  Â  Â  logger.error(f"[OPENAI] HTTP status error: {e.response.status_code} - {e.response.text}")
Â  Â  Â  Â  return [f"Feedback service returned an error: {e.response.status_code}"]
Â  Â  except (json.JSONDecodeError, Exception) as e:
Â  Â  Â  Â  logger.error(f"[OPENAI] API call or JSON decoding failed: {e.__class__.__name__}: {e}")
Â  Â  Â  Â  return [f"An error occurred during intelligent feedback generation: {e.__class__.__name__}"]

# --- Core Analysis Function (UPDATED) ---
def perform_analysis_job(
Â  Â  file_id: str,Â 
Â  Â  s3_key: str,Â 
Â  Â  transcript: str,Â 
Â  Â  user_id: Optional[str] = None
) -> Dict[str, Any]:
Â  Â  """Worker function to fetch audio, perform analysis, and return results."""
Â  Â  job_start_time = time.time()
Â  Â  logger.info(f"ðŸš€ Starting analysis for file_id: {file_id}, s3_key: {s3_key}")

Â  Â  temp_audio_file = f"/tmp/{file_id}_{os.path.basename(s3_key)}"
Â  Â  temp_wav_file = f"/tmp/{file_id}_converted.wav"
Â  Â Â 
Â  Â  # 1. Fluency analysis first (UPDATED FOR HIGHLIGHTING)
Â  Â  total_words = len(transcript.split())Â 
Â  Â  
    # Collect all text markers from the updated functions
    filler_apology_markers: List[TextMarker] = detect_fillers_and_apologies(transcript)
    repetition_markers: List[TextMarker] = detect_repetitions_for_highlighting(transcript)
    custom_markers: List[TextMarker] = detect_custom_markers(transcript)
    
    all_text_markers = filler_apology_markers + repetition_markers + custom_markers
    
    # Calculate counts for metrics based on the markers
    filler_word_count = len([m for m in all_text_markers if m.type == 'filler'])
    # Count specific repetitions and acoustic disfluencies separately as they contribute most to score
    repetition_count = len([m for m in all_text_markers if m.type == 'repetition']) 
    apology_count = len([m for m in all_text_markers if m.type == 'apology']) 
    
Â  Â  # Initialize values
Â  Â  duration_seconds = 0
Â  Â  speaking_pace_wpm = 0
Â  Â  emotion = "Neutral"
Â  Â  confidence_score = 0.0
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  # 2. Download (Original raw file)
Â  Â  Â  Â  logger.info(f"â¬‡ï¸ Downloading s3://{S3_BUCKET_NAME}/{s3_key}...")
Â  Â  Â  Â  s3_client.download_file(S3_BUCKET_NAME, s3_key, temp_audio_file)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 3. Safe Duration Check on the raw file
Â  Â  Â  Â  audio_features_raw = extract_audio_features(temp_audio_file)
Â  Â  Â  Â  audio_duration = audio_features_raw.get('duration_s', 0)
Â  Â  Â  Â Â 
Â  Â  Â  Â  if audio_duration > MAX_DURATION_SECONDS:
Â  Â  Â  Â  Â  Â  Â logger.warning(f"âš ï¸ Audio duration {audio_duration:.2f}s exceeds limit of {MAX_DURATION_SECONDS}s.")
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 4. Conversion to WAVÂ 
Â  Â  Â  Â  # NOTE: FFmpeg MUST be a system dependency installed on the worker.
Â  Â  Â  Â  ffmpeg_command = ["ffmpeg", "-i", temp_audio_file, "-ac", "1", "-ar", str(TARGET_SR), "-y", temp_wav_file]
Â  Â  Â  Â Â 
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  subprocess.run(ffmpeg_command, capture_output=True, text=True, check=True)
Â  Â  Â  Â  Â  Â  logger.info("âœ… FFmpeg conversion successful.")
Â  Â  Â  Â  except subprocess.CalledProcessError as e:
Â  Â  Â  Â  Â  Â  logger.error(f"âŒ FFmpeg conversion failed: {e.stderr}", exc_info=True)
Â  Â  Â  Â  Â  Â  raise Exception("FFmpeg conversion failed.")
Â  Â  Â  Â  except FileNotFoundError:
Â  Â  Â  Â  Â  Â  logger.error("âŒ FFmpeg command not found. Ensure FFmpeg is installed and in PATH.")
Â  Â  Â  Â  Â  Â  raise Exception("FFmpeg not available in the worker environment.")
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  # 5. Load the converted WAV fileÂ 
Â  Â  Â  Â  y, sr = sf.read(temp_wav_file, dtype='float32', always_2d=False)
Â  Â  Â  Â  if len(y.shape) > 1:
Â  Â  Â  Â  Â  Â  y = np.mean(y, axis=1)

Â  Â  Â  Â  # Truncate 'y' (if conversion didn't handle duration limit, or for safety)
Â  Â  Â  Â  max_samples = sr * MAX_DURATION_SECONDS
Â  Â  Â  Â  if len(y) > max_samples:
Â  Â  Â  Â  Â  Â  y = y[:max_samples]
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  duration_seconds = len(y) / sr
Â  Â  Â  Â  speaking_pace_wpm = (total_words / max(1, duration_seconds)) * 60

Â  Â  Â  Â  # 6. Feature Extraction & Acoustic Analysis
Â  Â  Â  Â  logger.info("ðŸ“ˆ Extracting audio features and metrics...")
Â  Â  Â  Â Â 
Â  Â  Â  Â  # --- Audio Feature Calculation (Numpy/SciPy based on 'y') ---
Â  Â  Â  Â  rms = np.sqrt(np.mean(y**2))Â 
Â  Â  Â  Â  avg_amplitude = np.mean(np.abs(y))
Â  Â  Â  Â  energy_std = np.std(np.abs(y))Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Simple silence calculation based on RMS frames
Â  Â  Â  Â  frame_len = int(sr * 0.05)Â 
Â  Â  Â  Â  hop_len = int(sr * 0.01)Â  Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  num_frames = (len(y) - frame_len) // hop_len + 1
Â  Â  Â  Â  rms_frames = np.array([np.sqrt(np.mean(y[i*hop_len : i*hop_len + frame_len]**2)) for i in range(num_frames)])
Â  Â  Â  Â Â 
Â  Â  Â  Â  rms_threshold = np.mean(rms_frames) * 0.1Â 
Â  Â  Â  Â  silence_frames = np.sum(rms_frames < rms_threshold)
Â  Â  Â  Â  total_frames = len(rms_frames)
Â  Â  Â  Â  silence_ratio = silence_frames / total_frames if total_frames > 0 else 0.0
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Simple proxy for long pause count
Â  Â  Â  Â  frames_per_half_second = int(0.5 / (hop_len / sr))
Â  Â  Â  Â  long_pause_count = len([i for i in range(len(rms_frames) - frames_per_half_second)Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if all(rms_frames[i+j] < rms_threshold for j in range(frames_per_half_second))])

Â  Â  Â  Â  # Uses the new NumPy/SciPy function
Â  Â  Â  Â  pitch_mean, pitch_std = calculate_pitch_stats(y, sr)
Â  Â  Â  Â Â 
Â  Â  Â  Â  audio_features_for_score = {
Â  Â  Â  Â  Â  Â  "rms_mean": float(rms),
Â  Â  Â  Â  Â  Â  "rms_std": float(energy_std),Â 
Â  Â  Â  Â  Â  Â  "speaking_pace_wpm": speaking_pace_wpm,
Â  Â  Â  Â  Â  Â  "pitch_std": float(pitch_std),
Â  Â  Â  Â  Â  Â  "pitch_mean": float(pitch_mean),
Â  Â  Â  Â  }
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Uses the new NumPy/SciPy function
Â  Â  Â  Â  acoustic_disfluencies = detect_acoustic_disfluencies(y, sr)
Â  Â  Â  Â  serializable_disfluencies = [d._asdict() for d in acoustic_disfluencies]
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Recalculate fluency metrics for scoring
Â  Â  Â  Â  fluency_metrics_for_score = {
Â  Â  Â  Â  Â  Â  "filler_word_count": filler_word_count,
Â  Â  Â  Â  Â  Â  "repetition_count": repetition_count,
Â  Â  Â  Â  Â  Â  "acoustic_disfluency_count": len(serializable_disfluencies),
Â  Â  Â  Â  Â  Â  "total_words": total_words,
Â  Â  Â  Â  }
Â  Â  Â  Â Â 
Â  Â  Â  Â  confidence_score = score_confidence(audio_features_for_score, fluency_metrics_for_score)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Emotion Classification
Â  Â  Â  Â  emotion = classify_emotion_simple(temp_wav_file, EMOTION_MODEL, EMOTION_SCALER)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 7. Compile Core Metrics for LLM (UPDATED)
Â  Â  Â  Â  core_analysis_metrics = {
Â  Â  Â  Â  Â  Â  "confidence_score": round(confidence_score, 2),
Â  Â  Â  Â  Â  Â  "speaking_pace": int(round(speaking_pace_wpm)),
Â  Â  Â  Â  Â  Â  "filler_word_count": filler_word_count,
            "apology_count": apology_count,
Â  Â  Â  Â  Â  Â  "repetition_count": repetition_count,
Â  Â  Â  Â  Â  Â  "acoustic_disfluencies": serializable_disfluencies,
Â  Â  Â  Â  Â  Â  "acoustic_disfluency_count": len(serializable_disfluencies),Â 
Â  Â  Â  Â  Â  Â  "long_pause_count": float(long_pause_count),
Â  Â  Â  Â  Â  Â  "silence_ratio": round(silence_ratio, 2),
Â  Â  Â  Â  Â  Â  "pitch_mean": round(float(pitch_mean), 2),
Â  Â  Â  Â  Â  Â  "pitch_std": round(float(pitch_std), 2),
Â  Â  Â  Â  Â  Â  "emotion": emotion.lower(),
Â  Â  Â  Â  Â  Â  "energy_std": round(float(energy_std), 4),
Â  Â  Â  Â  Â  Â  "transcript": transcript,
Â  Â  Â  Â  Â  Â  "total_words": total_words,
Â  Â  Â  Â  Â  Â  "duration_seconds": round(duration_seconds, 2),
Â  Â  Â  Â  Â  Â  # CRITICAL NEW FIELD
Â  Â  Â  Â  Â  Â  "highlight_markers": [m._asdict() for m in all_text_markers], 
Â  Â  Â  Â  }
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 8. Generate Intelligent Feedback
Â  Â  Â  Â  logger.info("ðŸ¤– Generating intelligent feedback using OpenAI...")
Â  Â  Â  Â  llm_recommendations = generate_intelligent_feedback(
Â  Â  Â  Â  Â  Â  transcript=transcript,Â 
Â  Â  Â  Â  Â  Â  metrics=core_analysis_metrics
Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 9. Compile Final Result
Â  Â  Â  Â  final_result = {
Â  Â  Â  Â  Â  Â  **core_analysis_metrics,
Â  Â  Â  Â  Â  Â  "recommendations": llm_recommendations,
Â  Â  Â  Â  }

Â  Â  Â  Â  logger.info(f"âœ… Analysis complete in {round(time.time() - job_start_time, 2)}s.")
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 10. Cleanup
Â  Â  Â  Â  if os.path.exists(temp_audio_file): os.remove(temp_audio_file)
Â  Â  Â  Â  if os.path.exists(temp_wav_file): os.remove(temp_wav_file)
Â  Â  Â  Â Â 
Â  Â  Â  Â  return final_result

Â  Â  except Exception as e:
Â  Â  Â  Â  logger.error(f"âŒ FATAL Analysis Error: {e}", exc_info=True)
Â  Â  Â  Â  if os.path.exists(temp_audio_file): os.remove(temp_audio_file)
Â  Â  Â  Â  if os.path.exists(temp_wav_file): os.remove(temp_wav_file)
Â  Â  Â  Â  raise

# --- Worker Entrypoint (Unchanged) ---
if __name__ == '__main__':
Â  Â  redis_url = os.getenv('REDIS_URL', 'redis://localhost:6379')
Â  Â  logger.info(f"Starting worker and connecting to Redis at: {redis_url}")
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  redis_conn = Redis.from_url(redis_url)
Â  Â  Â  Â  redis_conn.ping()
Â  Â  Â  Â  logger.info("âœ… Redis connection established")
Â  Â  Â  Â Â 
Â  Â  Â  Â  worker = Worker(['default'], connection=redis_conn)
Â  Â  Â  Â  worker.work()

Â  Â  except Exception as e:
Â  Â  Â  Â  logger.error(f"âŒ Worker failed to start: {e}", exc_info=True)
Â  Â  Â  Â  if 'redis' in str(e).lower():
Â  Â  Â  Â  Â  Â  logger.critical("âš ï¸ Check your REDIS_URL and network configuration.")
Â  Â  Â  Â  exit(1)
